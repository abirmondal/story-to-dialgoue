{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the project root to Python's import path so local modules (src/...) can be imported easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_path = Path.cwd().parent\n",
    "\n",
    "sys.path.append(str(project_path.resolve()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dataset helpers, Hugging Face Transformers and PEFT components used for training and tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T06:36:43.432669Z",
     "iopub.status.busy": "2025-10-26T06:36:43.432346Z",
     "iopub.status.idle": "2025-10-26T06:37:19.082233Z",
     "shell.execute_reply": "2025-10-26T06:37:19.081239Z",
     "shell.execute_reply.started": "2025-10-26T06:36:43.432576Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "from src.dataset.load_data_soda import SODADataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set finetuned model name from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T06:37:19.085284Z",
     "iopub.status.busy": "2025-10-26T06:37:19.084671Z",
     "iopub.status.idle": "2025-10-26T06:37:19.089687Z",
     "shell.execute_reply": "2025-10-26T06:37:19.088806Z",
     "shell.execute_reply.started": "2025-10-26T06:37:19.085256Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "BASE_MODEL_NAME = \"facebook/bart-base\"\n",
    "HF_LORA_MODEL_NAME = \"abirmondalind/story2dialogue-SODA-BERT-LoRA\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the SODA dataset loader with simple filtering options and retrieve the dataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T06:37:19.091195Z",
     "iopub.status.busy": "2025-10-26T06:37:19.090839Z",
     "iopub.status.idle": "2025-10-26T06:37:35.416377Z",
     "shell.execute_reply": "2025-10-26T06:37:35.415256Z",
     "shell.execute_reply.started": "2025-10-26T06:37:19.091162Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "soda_dataset_obj = SODADataLoader(\n",
    "    data_types=['test'],\n",
    "    samples_per_split=50,\n",
    "    min_story_length=20,\n",
    "    max_story_length=250,\n",
    "    join_dialogue_and_speakers=True,\n",
    "    add_characters_in_narrative=True,\n",
    "    add_turns_count_in_narrative=True\n",
    ")\n",
    "soda_ds = soda_dataset_obj.dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the fine-tuned LoRA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T06:37:35.418432Z",
     "iopub.status.busy": "2025-10-26T06:37:35.417525Z",
     "iopub.status.idle": "2025-10-26T06:37:39.253903Z",
     "shell.execute_reply": "2025-10-26T06:37:39.253121Z",
     "shell.execute_reply.started": "2025-10-26T06:37:35.418394Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_NAME)\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(BASE_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T06:37:39.255566Z",
     "iopub.status.busy": "2025-10-26T06:37:39.254896Z",
     "iopub.status.idle": "2025-10-26T06:37:43.661887Z",
     "shell.execute_reply": "2025-10-26T06:37:43.660965Z",
     "shell.execute_reply.started": "2025-10-26T06:37:39.255529Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = PeftModel.from_pretrained(base_model, HF_LORA_MODEL_NAME)\n",
    "model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create text2text generation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T06:37:43.663155Z",
     "iopub.status.busy": "2025-10-26T06:37:43.662811Z",
     "iopub.status.idle": "2025-10-26T06:37:43.670567Z",
     "shell.execute_reply": "2025-10-26T06:37:43.669473Z",
     "shell.execute_reply.started": "2025-10-26T06:37:43.663132Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "generator = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate dialogue from a narrative and compare with actual dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T06:37:43.672166Z",
     "iopub.status.busy": "2025-10-26T06:37:43.671780Z",
     "iopub.status.idle": "2025-10-26T06:38:21.516548Z",
     "shell.execute_reply": "2025-10-26T06:38:21.515659Z",
     "shell.execute_reply.started": "2025-10-26T06:37:43.672135Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "i = 10\n",
    "text = soda_ds['test'][i]['narrative']\n",
    "actual_dialogue = soda_ds['test'][i]['dialogue']\n",
    "\n",
    "output = generator(\n",
    "        text,\n",
    "        max_new_tokens=1024,\n",
    "        # min_length=150,\n",
    "        num_beams=8,\n",
    "        length_penalty=1.2,\n",
    "        # no_repeat_ngram_size=3,\n",
    "        early_stopping=True\n",
    "    )\n",
    "\n",
    "print(\"Narrative:\", text, \"\\n\", sep=\"\\n\")\n",
    "print(\"Generated Dialogue:\", output[0]['generated_text'], \"\\n\", sep=\"\\n\")\n",
    "print(\"Actual Dialogue:\", actual_dialogue, sep=\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
